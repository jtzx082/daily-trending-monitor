name: Q7DTD Key Crawler

on:
  # 定时触发（每天凌晨2点UTC）
  schedule:
    - cron: '0 2 * * *'
  
  # 手动触发
  workflow_dispatch:
    inputs:
      search_count:
        description: '每次查询的结果数量'
        required: false
        default: '10'
        type: string
  
  # Push触发（用于测试）
  push:
    branches: [ main ]

jobs:
  crawl:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run crawler
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
        GOOGLE_CX: ${{ secrets.GOOGLE_CX }}
      run: |
        echo "Starting Q7DTD crawler..."
        python src/crawler.py
    
    - name: Upload results as artifact
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: q7dtd-results
        path: results/
        retention-days: 7
    
    - name: Commit and push results
      if: github.ref == 'refs/heads/main'
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        
        # 检查是否有新文件
        if [ -n "$(git status --porcelain results/)" ]; then
          git add results/
          git commit -m "Update crawl results - $(date '+%Y-%m-%d %H:%M:%S')"
          git push
        else
          echo "No new results to commit"
        fi
    
    - name: Summary
      run: |
        echo "Crawler job completed!"
        echo "Check the artifacts for results."
