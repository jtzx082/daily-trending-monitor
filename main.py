import requests
from bs4 import BeautifulSoup
import datetime
import urllib.parse

# å®šä¹‰æ‚¨æƒ³è¦å…³æ³¨çš„å…³é”®è¯ï¼ˆå¯ä»¥åœ¨è¿™é‡Œéšæ„å¢å‡ï¼‰
KEYWORDS = [
    "é«˜ä¸­åŒ–å­¦",
    "ç­ä¸»ä»»å·¥ä½œ",
    "Gemini"
]

def fetch_bing_news_rss(keyword):
    # å°†å…³é”®è¯è½¬æ¢ä¸º URL ç¼–ç  (ä¾‹å¦‚: é«˜ä¸­ -> %E9%AB%98%E4%B8%AD)
    encoded_keyword = urllib.parse.quote(keyword)
    # Bing News RSS æ¥å£
    url = f"https://www.bing.com/news/search?q={encoded_keyword}&format=rss"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0'
    }

    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        # ä½¿ç”¨ xml è§£æå™¨
        soup = BeautifulSoup(response.content, 'xml')
        items = soup.find_all('item')
        
        news_list = []
        for item in items[:10]: # æ¯ä¸ªè¯é¢˜åªå–å‰10æ¡
            title = item.title.text
            link = item.link.text
            pub_date = item.pubDate.text if item.pubDate else ""
            
            # ç®€å•çš„æ—¥æœŸæ ¼å¼åŒ–ï¼Œå»æ‰å¤šä½™çš„æ—¶åŒºä¿¡æ¯
            if len(pub_date) > 16:
                pub_date = pub_date[:16]
                
            news_list.append({
                "title": title,
                "link": link,
                "date": pub_date
            })
            
        return news_list

    except Exception as e:
        print(f"è·å– [{keyword}] å¤±è´¥: {e}")
        return []

def generate_markdown(data_dict):
    md = f"# ğŸ« æ•™è‚²ä¸ç§‘æŠ€æ—¥æŠ¥\n\n"
    md += f"**æ›´æ–°æ—¶é—´**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')} (UTC)\n\n"
    md += "> æœ¬æ—¥æŠ¥ç”± GitHub Actions è‡ªåŠ¨ç”Ÿæˆï¼Œæ•°æ®æ¥æº Bing Newsã€‚\n\n"

    for keyword, news_items in data_dict.items():
        md += f"## ğŸ“Œ {keyword}\n\n"
        if not news_items:
            md += "ä»Šæ—¥æš‚æ— ç›¸å…³æ–°é—»ã€‚\n\n"
            continue
            
        md += "| æ–°é—»æ ‡é¢˜ | å‘å¸ƒæ—¶é—´ |\n"
        md += "|---|---|\n"
        for news in news_items:
            # æ¸…ç†æ ‡é¢˜ä¸­çš„ Bing é«˜äº®æ ‡ç­¾
            clean_title = news['title'].replace(f"{keyword}", f"**{keyword}**")
            md += f"| [{clean_title}]({news['link']}) | {news['date']} |\n"
        md += "\n"
        
    return md

def main():
    all_news = {}
    
    for keyword in KEYWORDS:
        print(f"æ­£åœ¨æŠ“å–: {keyword} ...")
        news = fetch_bing_news_rss(keyword)
        all_news[keyword] = news
    
    # ç”Ÿæˆ Markdown å†…å®¹
    content = generate_markdown(all_news)
    
    # ä¿å­˜æ–‡ä»¶
    with open("README.md", "w", encoding="utf-8") as f:
        f.write(content)
    print("README.md æ›´æ–°æˆåŠŸï¼")

if __name__ == "__main__":
    main()
