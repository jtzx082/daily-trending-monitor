import requests
from bs4 import BeautifulSoup
import datetime
import os

def scrape_github_trending():
    url = "https://github.com/trending"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0'
    }

    try:
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        repo_list = soup.select('article.Box-row') # è·å–æ‰€æœ‰é¡¹ç›®å¡ç‰‡
        
        markdown_content = f"# ğŸ“ˆ GitHub å¼€æºé¡¹ç›®æ—¥æŠ¥\n\n"
        markdown_content += f"**æ›´æ–°æ—¶é—´**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')} (UTC)\n\n"
        markdown_content += "| é¡¹ç›®åç§° | ç®€ä»‹ | Stars |\n"
        markdown_content += "|---|---|---|\n"

        for repo in repo_list[:15]: # åªå–å‰15ä¸ª
            # 1. æå–é¡¹ç›®åç§°å’Œé“¾æ¥
            h1 = repo.select_one('h1')
            link = h1.select_one('a')
            name = link.text.strip().replace('\n', '').replace(' ', '')
            href = f"https://github.com{link['href']}"
            
            # 2. æå–æè¿° (æœ‰äº›é¡¹ç›®æ²¡æœ‰æè¿°ï¼Œéœ€è¦å®¹é”™)
            desc_tag = repo.select_one('p.col-9')
            desc = desc_tag.text.strip() if desc_tag else "æš‚æ— æè¿°"
            
            # 3. æå–ä»Šæ—¥ Star æ•° (é€šå¸¸åœ¨æœ€åä¸€ä¸ª svg åé¢)
            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œç›´æ¥æ‰¾åŒ…å« 'stars today' çš„æ–‡æœ¬
            stars_today = "N/A"
            span_tags = repo.select('span.d-inline-block.float-sm-right')
            if span_tags:
                stars_today = span_tags[0].text.strip()
            
            # ä¸ºäº†é˜²æ­¢ Markdown è¡¨æ ¼é”™ä¹±ï¼Œæ›¿æ¢æ‰æè¿°é‡Œçš„ç«–çº¿
            desc = desc.replace('|', '/')
            
            markdown_content += f"| [{name}]({href}) | {desc} | {stars_today} |\n"

        return markdown_content

    except Exception as e:
        print(f"çˆ¬å–å¤±è´¥: {e}")
        return None

def save_to_file(content):
    # å°†ç»“æœä¿å­˜ä¸º README.mdï¼Œè¿™æ ·ç›´æ¥åœ¨ä»“åº“é¦–é¡µå°±èƒ½çœ‹åˆ°
    with open("README.md", "w", encoding="utf-8") as f:
        f.write(content)
    print("æ–‡ä»¶å·²æ›´æ–°: README.md")

if __name__ == "__main__":
    content = scrape_github_trending()
    if content:
        save_to_file(content)
